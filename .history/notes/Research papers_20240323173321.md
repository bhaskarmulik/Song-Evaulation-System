***Paper 1 : A Dataset and Baseline System for Singing Voice Assessment***

1. **Distance Signal**: The distance signal is created by comparing the fundamental frequency (f0) series of a singing performance with a reference (usually a piano) f0 series. This comparison is done using Dynamic Time Warping (DTW), which aligns the two series in time, allowing for an accurate comparison despite any timing differences.

2. **Histogram Creation**: After obtaining the distance signal from DTW, a histogram is computed. This histogram has a predefined number of bins (150 in the case mentioned in the document) and represents the distribution of the distances between the two f0 series. The idea is that certain distances will be more common in good singing performances (close to the reference) and others in poor ones (far from the reference or with octave errors).

3. **Input Feature**: The histogram serves as the input feature for the logistic regression model. Each bin of the histogram effectively becomes a feature that describes the singing performance. The model uses these features to learn patterns that distinguish between high and low-quality singing.

4. **Model Training**: During training, the logistic regression model learns the weights (coefficients) for each histogram bin that best predict the quality of singing. The model learns to associate certain histogram patterns with high-quality singing and others with low-quality singing.

5. **Quality Assessment**: When assessing a new singing performance, the same process is followed to create a histogram from the distance signal. This histogram is then input into the trained logistic regression model, which outputs a probability score indicating the likelihood that the performance is of high quality.

This method allows for an objective assessment of singing quality based on the comparison of the singer's performance with a known reference, and the histogram captures the nuances of this comparison in a form that the logistic regression model can use for classification.

Source: Conversation with Bing, 23/3/2024
(1) A Dataset and Baseline System for Singing Voice Assessment. https://www.academia.edu/38019278/A_Dataset_and_Baseline_System_for_Singing_Voice_Assessment.
(2) Histogram-Based Gradient Boosting Ensembles in Python. https://machinelearningmastery.com/histogram-based-gradient-boosting-ensembles/.
(3) Logistic Regression in Python - A Step-by-Step Guide. https://www.nickmccullum.com/python-machine-learning/logistic-regression-python/.

***Paper 2 : A Review of Singing Evaluation Algorithms***  
The document describes the **Dynamically-Aligned Pitch Comparison** method as follows:

- It addresses the issue of the simple pitch comparison method being overly sensitive to the caller falling slightly out of time compared to the reference clip.
- To compensate for timing differences, it performs a *Viterbi alignment* of the caller's pitch curve with the reference pitch curve.
- After alignment, the total difference in pitch is used as a distance metric.Using a probabilistic approach may yield better results than a deterministic approach.
- This metric is then transformed into a rating out of ten to indicate to the user how close their performance was to the original singer.

Additionally, the document mentions that this method can penalize humming by combining the pitch-based score with a confidence score from a speech recognizer¹².

    Viterbi Alignment: This process involves aligning the pitch curves of the caller's recording with the reference recording. The Viterbi algorithm, a dynamic programming algorithm, is used to find the most likely sequence of hidden states that results in a sequence of observed events. In the context of pitch comparison, the observed events are the pitch samples from the caller's singing, and the hidden states are the corresponding pitch samples in the reference clip. The algorithm aligns these two sequences to minimize the total difference in pitch, even if the caller's timing is slightly off compared to the reference. This alignment allows for a more accurate comparison of pitch, taking into account timing differences between the two performances. The resulting distance metric can then be used to provide feedback to the user on the quality of their singing performance.

***Paper 3: Perceptual Evaluation of Singing Quality***

    Dynamic Time Warping (DTW) is an algorithm used for measuring the similarity between two temporal sequences which may vary in speed. It's particularly useful in fields like speech recognition, data mining, and financial markets. Here's a high-level explanation of how it works:
1. **Alignment**: DTW aligns two sequences, \( X \) and \( Y \), which may not be of the same length, to identify the points in time that correspond to each other.

2. **Grid Formation**: The sequences are arranged to form an \( n \)-by-\( m \) grid, where each point \((i, j)\) represents the alignment between \( x[i] \) and \( y[j] \).

3. **Warping Path**: A warping path \( W \) is determined, which maps the elements of \( X \) and \( Y \) to minimize the distance between them. This path is a sequence of grid points \((i, j)\).

4. **Cost Calculation**: The optimal path to the end point \((n, m)\) is computed by finding the path that has the minimal cost, where the cost is computed as the sum of absolute differences between matched pairs of indices.

5. **Constraints**: DTW uses a dynamic programming approach to find the optimal path while adhering to certain constraints like boundary conditions, monotonicity, and continuity to ensure the path is realistic and efficient.

6. **Result**: The output of DTW is the cumulative distance between the two sequences along the warping path, which represents how similar they are, despite potential differences in speed or timing.

DTW is powerful because it can find an optimal match between sequences even if they are not aligned in time, allowing for a flexible comparison that accounts for variations in speed or duration¹².